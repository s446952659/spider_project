# -*- coding: utf-8 -*-
import scrapy
import datetime
import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from Astock.items import XueqiuFinanceItem
from Astock.settings import filepathcfg,NOWSYSTEM


class ChinaXueqiuFinanceSpider(scrapy.Spider):
    name = 'ChinaXueqiuFinance'
    allowed_domains = ['stock.xueqiu.com']
    start_urls = ['https://stock.xueqiu.com/v5/stock/finance/cn/balance.json?symbol=SZ000001&type=all&is_detail=true&count=200']
    chrome_options = Options()
    chrome_options.add_argument('--headless')

    def __init__(self):
        super(ChinaXueqiuFinanceSpider, self).__init__()
        # 获取接口token
        driver = webdriver.Chrome(options=self.chrome_options)
        driver.get('https://xueqiu.com/snowman/S/SZ000001/detail#/GSLRB')
        cookie = driver.get_cookies()
        self.xq_a_token = cookie[-2]['value']
        driver.quit()
        self.crawl_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        self.A_stocks = pd.read_excel(filepathcfg[NOWSYSTEM]['CHINAXUEQIUFILEPATH'], dtype={'code': str, 'market': str})

    def parse(self,response):
        for i in self.A_stocks.index:
            stock_code = self.A_stocks['code'][i]
            stock_market = self.A_stocks['market'][i]
            stock_name = self.A_stocks['name'][i]
            debt_report_url = 'https://stock.xueqiu.com/v5/stock/finance/cn/balance.json?symbol=%s&type=all&is_detail=true&count=200'%stock_code
            yield scrapy.Request(url=debt_report_url, callback=self.parse_debt_report, dont_filter=True,
                                 meta={"info": (stock_code, stock_market, stock_name)})

    #资产负债按期报告
    def parse_debt_report(self, response):
        stock_code,stock_market,stock_name = response.meta.get('info')
        debt_report = response.text
        debt_year_url = 'https://stock.xueqiu.com/v5/stock/finance/cn/balance.json?symbol=%s&type=Q4&is_detail=true&count=50'%stock_code
        yield scrapy.Request(url=debt_year_url, callback=self.parse_debt_year, dont_filter=True,
                             meta={"info":(stock_code,stock_market,stock_name,debt_report)})

    #资产负债按年度报告
    def parse_debt_year(self,response):
        stock_code,stock_market,stock_name,debt_report=response.meta.get("info")
        debt_year = response.text
        debt_quarter_url = 'https://stock.xueqiu.com/v5/stock/finance/cn/balance.json?symbol=%s&type=S0&is_detail=true&count=150'%stock_code
        yield scrapy.Request(url=debt_quarter_url, callback=self.parse_debt_quarter, dont_filter=True,
                             meta={"info":(stock_code,stock_market,stock_name,debt_report,debt_year)})

    #资产负债按季度报告
    def parse_debt_quarter(self,response):
        stock_code,stock_market,stock_name,debt_report,debt_year = response.meta.get("info")
        debt_quarter = response.text
        benifit_report_url = 'https://stock.xueqiu.com/v5/stock/finance/cn/income.json?symbol=%s&type=all&is_detail=true&count=200'%stock_code
        yield scrapy.Request(url=benifit_report_url, callback=self.parse_benifit_report, dont_filter=True,
                             meta={"info": (stock_code,stock_market,stock_name,debt_report,debt_year,
                                            debt_quarter)})

    def parse_benifit_report(self,response):
        stock_code, stock_market, stock_name, debt_report, debt_year,debt_quarter = response.meta.get("info")
        benifit_report = response.text
        benifit_year_url = 'https://stock.xueqiu.com/v5/stock/finance/cn/income.json?symbol=%s&type=Q4&is_detail=true&count=50'%stock_code
        yield scrapy.Request(url=benifit_year_url, callback=self.parse_benifit_year, dont_filter=True,
                             meta={"info": (stock_code, stock_market, stock_name, debt_report, debt_year,
                                            debt_quarter,benifit_report)})

    def parse_benifit_year(self,response):
        stock_code,stock_market,stock_name,debt_report,debt_year,debt_quarter,benifit_report = response.meta.get("info")
        benifit_year = response.text
        benifit_quarter_url = 'https://stock.xueqiu.com/v5/stock/finance/cn/income.json?symbol=%s&type=S0&is_detail=true&count=150'%stock_code
        yield scrapy.Request(url=benifit_quarter_url, callback=self.parse_benifit_quarter, dont_filter=True,
                             meta={"info": (stock_code, stock_market, stock_name, debt_report, debt_year,
                                            debt_quarter, benifit_report,benifit_year)})

    def parse_benifit_quarter(self,response):
        stock_code,stock_market,stock_name,debt_report,debt_year,debt_quarter,benifit_report,benifit_year= response.meta.get(
            "info")
        benifit_quarter = response.text
        cash_report_url = 'https://stock.xueqiu.com/v5/stock/finance/cn/cash_flow.json?symbol=%s&type=all&is_detail=true&count=200'%stock_code
        yield scrapy.Request(url=cash_report_url, callback=self.parse_cash_report, dont_filter=True,
                             meta={"info": (stock_code, stock_market, stock_name, debt_report, debt_year,
                                            debt_quarter, benifit_report, benifit_year,benifit_quarter)})

    def parse_cash_report(self,response):
        stock_code, stock_market, stock_name, \
        debt_report, debt_year, debt_quarter, \
        benifit_report, benifit_year,benifit_quarter = response.meta.get("info")
        cash_report = response.text
        cash_year_url = 'https://stock.xueqiu.com/v5/stock/finance/cn/cash_flow.json?symbol=%s&type=Q4&is_detail=true&count=50'%stock_code
        yield scrapy.Request(url=cash_year_url, callback=self.parse_cash_year, dont_filter=True,
                             meta={"info": (stock_code, stock_market, stock_name, debt_report, debt_year,
                                            debt_quarter, benifit_report, benifit_year, benifit_quarter,
                                            cash_report,)})

    def parse_cash_year(self,response):
        stock_code, stock_market, stock_name, \
        debt_report, debt_year, debt_quarter, \
        benifit_report, benifit_year, benifit_quarter, \
        cash_report    = response.meta.get("info")
        cash_year = response.text
        cash_quarter_url = 'https://stock.xueqiu.com/v5/stock/finance/cn/cash_flow.json?symbol=%s&type=S0&is_detail=true&count=150'%stock_code
        yield scrapy.Request(url=cash_quarter_url, callback=self.parse_cash_quarter, dont_filter=True,
                             meta={"info": (stock_code, stock_market, stock_name, debt_report, debt_year,
                                            debt_quarter, benifit_report, benifit_year, benifit_quarter,
                                            cash_report,cash_year)})

    def parse_cash_quarter(self,response):
        stock_code, stock_market, stock_name, \
        debt_report, debt_year, debt_quarter, \
        benifit_report, benifit_year, benifit_quarter, \
        cash_report,cash_year = response.meta.get("info")
        cash_quarter = response.text
        item = XueqiuFinanceItem(stock_code=stock_code[2:],stock_market=stock_market,stock_name=stock_name,
                                 debt_report=debt_report,debt_year=debt_year,debt_quarter=debt_quarter,
                                 benifit_report=benifit_report,benifit_year=benifit_year,benifit_quarter=benifit_quarter,
                                 cash_report=cash_report,cash_year=cash_year,cash_quarter=cash_quarter,
                                 crawl_time=self.crawl_time)
        yield item



